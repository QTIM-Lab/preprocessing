{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf795959-4bae-4e16-ace2-1d12aadb3d58",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4af3f07-6548-4161-8ba1-cada69dd4ae7",
   "metadata": {},
   "source": [
    "## DICOM Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc74fa7e-caf4-46ab-b9d1-c87beb8ba56a",
   "metadata": {},
   "source": [
    "### Find (and optionally Reorganize) DICOMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4693da94-a9eb-4381-b676-09392d1f41aa",
   "metadata": {},
   "source": [
    "CLI example:\n",
    "\n",
    "For a publicly available dataset: [upenn-gbm](https://portal.imaging.datacommons.cancer.gov/explore/filters/?collection_id=upenn_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3726dd7f-c769-408e-9246-dca8f5ccf1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: preprocessing <command> [<args>]\n",
      "\n",
      "The following commands are available:\n",
      "    validate-installation       Check that the `preprocessing` library is installed correctly along\n",
      "                                with all of its dependencies.\n",
      "\n",
      "    dicom-dataset               Create a DICOM dataset CSV compatible with subsequent `preprocessing`\n",
      "                                scripts. The final CSV provides a series level summary of the location\n",
      "                                of each series alongside metadata extracted from DICOM headers.  If the\n",
      "                                previous organization schems of the dataset does not enforce a DICOM\n",
      "                                series being isolated to a unique directory (instances belonging to\n",
      "                                multiple series must not share the same lowest level directory),\n",
      "                                reorganization must be applied for NIfTI conversion.\n",
      "\n",
      "    nifti-dataset               Create a NIfTI dataset CSV compatible with subsequent `preprocessing`\n",
      "                                scripts. The final CSV provides a series level summary of the location\n",
      "                                of each series alongside metadata generated to simulate DICOM headers.\n",
      "                                Specifically, ['PatientID', 'StudyDate', 'SeriesInstanceUID',\n",
      "                                'SeriesDescription', 'StudyInstanceUID'] (and optionally\n",
      "                                'NormalizedSeriesDescription') are inferred or randomly generated.\n",
      "\n",
      "    dataset-to-nifti            Convert DICOMs to NIfTI file format. A CSV is required to map a\n",
      "                                DICOM series to the resulting .nii.gz file and to provide\n",
      "                                the context for filenames. The outputs will follow a BIDS inspired\n",
      "                                convention.\n",
      "\n",
      "    brain-preprocessing         Preprocess NIfTI files for deep learning. A CSV is required to\n",
      "                                indicate the location of source files and to procide the context\n",
      "                                for filenames. The outputs will follow a BIDS inspired convention.\n",
      "\n",
      "    track-tumors                Longitudinal tracking of individual tumors. Each connected component\n",
      "                                for a given label within a segmentation mask is assigned a unique ID\n",
      "                                that will remain consistent across all scans belonging to the same\n",
      "                                patient. This command assumes that longitudinal or atlas registration\n",
      "                                was used when preprocessing the data.\n",
      "\n",
      "Run `preprocessing <command> --help` for more details about how to use each individual command. dicom-dataset\n",
      "       [-h] [--reorg-dir REORG_DIR] [-a {is_anon,auto,deferred}] [-b BATCH]\n",
      "       [--assume-extension] [-m {arbitrary,midas}] [-c CPUS]\n",
      "       dicom-dir csv\n",
      "\n",
      "Create a DICOM dataset CSV compatible with subsequent `preprocessing` scripts.\n",
      "The final CSV provides a series level summary of the location of each series\n",
      "alongside metadata extracted from DICOM headers. If the previous organization\n",
      "schems of the dataset does not enforce a DICOM series being isolated to a\n",
      "unique directory (instances belonging to multiple series must not share the\n",
      "same lowest level directory), reorganization must be applied for NIfTI\n",
      "conversion.\n",
      "\n",
      "positional arguments:\n",
      "  dicom-dir             The directory in which the DICOM data is originally\n",
      "                        stored.\n",
      "  csv                   The filepath of the output CSV which defines the\n",
      "                        constructed dataset. A corresponding instance level\n",
      "                        CSV will also be written out.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --reorg-dir REORG_DIR\n",
      "                        The directory to which files are reorganized if a\n",
      "                        value other than `None` is provided. Defaults to\n",
      "                        `None`.\n",
      "  -a {is_anon,auto,deferred}, --anon {is_anon,auto,deferred}\n",
      "                        The anonymization scheme to apply to the completed\n",
      "                        CSV. Choose from: 'is_anon' Assumes the data is\n",
      "                        already anonymized and uses the 'PatientID' and\n",
      "                        'StudyDate' values. 'auto' Apply automated\n",
      "                        anonymization to the CSV. This function assumes that\n",
      "                        the 'PatientID' and 'StudyID' tags are consistent and\n",
      "                        correct to derive 'AnonPatientID' = 'sub_{i:02d}' and\n",
      "                        'AnonStudyID' = 'ses_{i:02d}'. 'deferred' Skip\n",
      "                        anonymization of the generated CSV. This step will be\n",
      "                        required for subsequent scripts.\n",
      "  -b BATCH, --batch BATCH\n",
      "                        The size of the groups of files on which metadata\n",
      "                        extraction is applied.\n",
      "  --assume-extension    Assume that the DICOM instances all share the '.dcm'\n",
      "                        file extension.\n",
      "  -m {arbitrary,midas}, --mode {arbitrary,midas}\n",
      "                        The assumed data orgnaization scheme under\n",
      "                        `dicom_dir`. The choices are ['arbitrary', 'midas'].\n",
      "                        Defaults to 'arbitrary'.\n",
      "  -c CPUS, --cpus CPUS  Number of cpus to use for multiprocessing. Defaults to\n",
      "                        1 (no multiprocessing).\n"
     ]
    }
   ],
   "source": [
    "!preprocessing dicom-dataset --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1cc9e30-54d4-4ec2-b6ba-70c26ccd8227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing DICOM dataset: 100%|█████▉| 839990/840621 [18:38<00:00, 751.06it/s]\n",
      "Dataset of DICOM instances saved to /autofs/space/crater_001/tools/repos/preprocessing_dev/notebooks/dicom_dataset_examples/upenn_gbm_dataset_instances.csv\n",
      "Anonymizing dataset: 100%|██████████████████| 630/630 [00:00<00:00, 1177.71it/s]\n",
      "Anonymization completed\n",
      "Dataset written to /autofs/space/crater_001/tools/repos/preprocessing_dev/notebooks/dicom_dataset_examples/upenn_gbm_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "!preprocessing dicom-dataset \\\n",
    "    /autofs/space/crater_001/datasets/public/NIH_IDC_Brain/upenn_gbm \\\n",
    "    dicom_dataset_examples/upenn_gbm_dataset.csv \\\n",
    "    -c 80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5147a3d1-da7c-4969-84f6-0e6d79ed55b0",
   "metadata": {},
   "source": [
    "Python API example:\n",
    "\n",
    "For a publically available dataset: [remind](https://portal.imaging.datacommons.cancer.gov/explore/filters/?collection_id=remind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1ce559d-529f-4b47-b95e-2d21b1def528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function create_dicom_dataset in module preprocessing.data.datasets:\n",
      "\n",
      "create_dicom_dataset(dicom_dir: pathlib.Path | str, dataset_csv: pathlib.Path | str, reorg_dir: pathlib.Path | str | None = None, anon: Literal['is_anon', 'auto', 'deferred'] = 'auto', batch_size: int = 1000, file_extension: Literal['*', '*.dcm'] = '*', mode: Literal['arbitrary', 'midas'] = 'arbitrary', cpus: int = 1)\n",
      "    Create a DICOM dataset CSV compatible with subsequent `preprocessing`\n",
      "    scripts. The final CSV provides a series level summary of the location\n",
      "    of each series alongside metadata extracted from DICOM headers.  If the\n",
      "    previous organization schems of the dataset does not enforce a DICOM\n",
      "    series being isolated to a unique directory (instances belonging to\n",
      "    multiple series must not share the same lowest level directory),\n",
      "    reorganization must be applied for NIfTI conversion.\n",
      "    \n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    dicom_dir: Path | str\n",
      "        The directory in which the DICOM data is originally stored.\n",
      "    \n",
      "    dataset_csv: Path | str\n",
      "        The filepath of the output CSV which defines the constructed\n",
      "        dataset. A corresponding instance level CSV will also be written\n",
      "        out.\n",
      "    \n",
      "    reorg_dir: Path | str | None\n",
      "        The directory to which files are reorganized if a value\n",
      "        other than `None` is provided. Defaults to `None`.\n",
      "    \n",
      "    anon: str\n",
      "        The anonymization scheme to apply to the completed CSV. Choose\n",
      "        from:\n",
      "            'is_anon'\n",
      "                Assumes the data is already anonymized and uses the\n",
      "                'PatientID' and 'StudyDate' values.\n",
      "    \n",
      "            'auto'\n",
      "                Apply automated anonymization to the CSV. This function\n",
      "                assumes that the 'PatientID' and 'StudyID' tags are\n",
      "                consistent and correct to derive 'AnonPatientID' = 'sub_{i:02d}'\n",
      "                and 'AnonStudyID' = 'ses_{i:02d}'.\n",
      "    \n",
      "            'deferred'\n",
      "                Skip anonymization of the generated CSV. This step will be\n",
      "                required for subsequent scripts.\n",
      "    \n",
      "    batch_size: int\n",
      "        The size of the groups of files on which metadata extraction is applied.\n",
      "    \n",
      "    file_extension: str\n",
      "        The assumed file extension used to identify DICOMs. The choices\n",
      "        are ['*', '*.dcm']. Defaults to '*'.\n",
      "    \n",
      "    mode: str\n",
      "        The assumed data orgnaization scheme under `dicom_dir`. The choices\n",
      "        are ['arbitrary', 'midas']. Defaults to 'arbitrary'.\n",
      "    \n",
      "    cpus: int\n",
      "        Number of cpus to use for multiprocessing. Defaults to 1 (no multiprocessing).\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    None\n",
      "        This function does not return anything+, but a CSV is generated to the location\n",
      "        specified by `dataset_csv`. An instance level CSV is also generated to `str(dataset_csv).replace('.csv', '_instances.csv')`.\n",
      "        An error file is potentially generated to the same parent directory of these CSVs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from preprocessing.data import create_dicom_dataset\n",
    "help(create_dicom_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3bc759c-acc9-457d-ab90-e747e687a865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructing DICOM dataset: 90419it [03:21, 448.13it/s]                                                                                                                                                                                                                                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset of DICOM instances saved to /autofs/space/crater_001/tools/repos/preprocessing_dev/notebooks/dicom_dataset_examples/remind_dataset_instances.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Anonymizing dataset: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 114/114 [00:00<00:00, 1790.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anonymization completed\n",
      "Dataset written to /autofs/space/crater_001/tools/repos/preprocessing_dev/notebooks/dicom_dataset_examples/remind_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "create_dicom_dataset(\n",
    "    dicom_dir=\"/autofs/space/crater_001/datasets/public/NIH_IDC_Brain/remind\",\n",
    "    dataset_csv=\"dicom_dataset_examples/remind_dataset.csv\",\n",
    "    cpus=80\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5471af21-7557-421c-9adb-99b2bb7d5f5f",
   "metadata": {},
   "source": [
    "Remember that subsequent commands require data to be converted from DICOM to the NIfTI file format. See [DICOM to NIfTI Conversion](#DICOM-to-NIfTI-Conversion) for more information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6d814f-33d1-4ca2-9898-726428838bd8",
   "metadata": {},
   "source": [
    "## NIfTI Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b0d4a86-d402-4323-b3e1-0c62f76af1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: preprocessing <command> [<args>]\n",
      "\n",
      "The following commands are available:\n",
      "    validate-installation       Check that the `preprocessing` library is installed correctly along\n",
      "                                with all of its dependencies.\n",
      "\n",
      "    dicom-dataset               Create a DICOM dataset CSV compatible with subsequent `preprocessing`\n",
      "                                scripts. The final CSV provides a series level summary of the location\n",
      "                                of each series alongside metadata extracted from DICOM headers.  If the\n",
      "                                previous organization schems of the dataset does not enforce a DICOM\n",
      "                                series being isolated to a unique directory (instances belonging to\n",
      "                                multiple series must not share the same lowest level directory),\n",
      "                                reorganization must be applied for NIfTI conversion.\n",
      "\n",
      "    nifti-dataset               Create a NIfTI dataset CSV compatible with subsequent `preprocessing`\n",
      "                                scripts. The final CSV provides a series level summary of the location\n",
      "                                of each series alongside metadata generated to simulate DICOM headers.\n",
      "                                Specifically, ['PatientID', 'StudyDate', 'SeriesInstanceUID',\n",
      "                                'SeriesDescription', 'StudyInstanceUID'] (and optionally\n",
      "                                'NormalizedSeriesDescription') are inferred or randomly generated.\n",
      "\n",
      "    dataset-to-nifti            Convert DICOMs to NIfTI file format. A CSV is required to map a\n",
      "                                DICOM series to the resulting .nii.gz file and to provide\n",
      "                                the context for filenames. The outputs will follow a BIDS inspired\n",
      "                                convention.\n",
      "\n",
      "    brain-preprocessing         Preprocess NIfTI files for deep learning. A CSV is required to\n",
      "                                indicate the location of source files and to procide the context\n",
      "                                for filenames. The outputs will follow a BIDS inspired convention.\n",
      "\n",
      "    track-tumors                Longitudinal tracking of individual tumors. Each connected component\n",
      "                                for a given label within a segmentation mask is assigned a unique ID\n",
      "                                that will remain consistent across all scans belonging to the same\n",
      "                                patient. This command assumes that longitudinal or atlas registration\n",
      "                                was used when preprocessing the data.\n",
      "\n",
      "Run `preprocessing <command> --help` for more details about how to use each individual command. nifti-dataset\n",
      "       [-h] [-a {is_anon,auto,deferred}] [-b BATCH] [-ss SEG_SERIES]\n",
      "       [-st SEG_TARGET] [-c CPUS]\n",
      "       nifti-dir csv file-pattern\n",
      "\n",
      "Create a NIfTI dataset CSV compatible with subsequent `preprocessing` scripts.\n",
      "The final CSV provides a series level summary of the location of each series\n",
      "alongside metadata generated to simulate DICOM headers. Specifically,\n",
      "['PatientID', 'StudyDate', 'SeriesInstanceUID', 'SeriesDescription',\n",
      "'StudyInstanceUID'] (and optionally 'NormalizedSeriesDescription') are\n",
      "inferred or randomly generated.\n",
      "\n",
      "positional arguments:\n",
      "  nifti-dir             The directory in which the DICOM data is originally\n",
      "                        stored.\n",
      "  csv                   The filepath of the output CSV which defines the\n",
      "                        constructed dataset.\n",
      "  file-pattern          The file naming convention (without file extensions)\n",
      "                        of NIfTIs within a dataset. Variable names are encoded\n",
      "                        using '{}' (e.g. `file_pattern` =\n",
      "                        '{patient}_{study}_{series}' would find values for the\n",
      "                        `patient`, `study`, and `series` variables). The\n",
      "                        `patient`, `study`, and `series` variables must be\n",
      "                        defined.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -a {is_anon,auto,deferred}, --anon {is_anon,auto,deferred}\n",
      "                        The anonymization scheme to apply to the completed\n",
      "                        CSV. Choose from: 'is_anon' Assumes the data is\n",
      "                        already anonymized and uses the 'PatientID' and\n",
      "                        'StudyDate' values. 'auto' Apply automated\n",
      "                        anonymization to the CSV. This function assumes that\n",
      "                        the 'PatientID' and 'StudyID' tags are consistent and\n",
      "                        correct to derive 'AnonPatientID' = 'sub_{i:02d}' and\n",
      "                        'AnonStudyID' = 'ses_{i:02d}'. 'deferred' Skip\n",
      "                        anonymization of the generated CSV. This step will be\n",
      "                        required for subsequent scripts.\n",
      "  -b BATCH, --batch BATCH\n",
      "                        The size of the groups of files on which metadata\n",
      "                        extraction is applied.\n",
      "  -ss SEG_SERIES, --seg-series SEG_SERIES\n",
      "                        The series description of segmentations within the\n",
      "                        dataset, assuming a consistent value is present. Must\n",
      "                        also specify `seg_target` to handle segmentations\n",
      "                        properly. Defaults to `None`.\n",
      "  -st SEG_TARGET, --seg-target SEG_TARGET\n",
      "                        The series description of the series from which\n",
      "                        segmentations are derived, assuming a consistent value\n",
      "                        is present. Must also specify `seg_series` to handle\n",
      "                        segmentations properly. Defaults to `None`.\n",
      "  -c CPUS, --cpus CPUS  Number of cpus to use for multiprocessing. Defaults to\n",
      "                        1 (no multiprocessing).\n"
     ]
    }
   ],
   "source": [
    "!preprocessing nifti-dataset --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee77295-e29e-4e06-afa0-955d217aa1e7",
   "metadata": {},
   "source": [
    "## DICOM to NIfTI Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28d2bee1-3e00-4c53-860e-4ea7ff4a3f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function convert_batch_to_nifti in module preprocessing.data.nifti_conversion:\n",
      "\n",
      "convert_batch_to_nifti(nifti_dir: pathlib.Path | str, csv: pathlib.Path | str, seg_source: str | None = None, overwrite_nifti: bool = False, cpus: int = 1, check_columns: bool = True) -> pandas.core.frame.DataFrame\n",
      "    Convert a DICOM dataset to NIfTI files representing each series.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    nifti_dir: Path | str\n",
      "        The root directory under which the converted NIfTI files will be written. Subdirectories\n",
      "        will be created to follow a BIDS inspired convention.\n",
      "    \n",
      "    csv: Path | str\n",
      "        The path to a CSV containing an entire dataset. It must contain the following\n",
      "        columns: ['Dicoms', 'AnonPatientID', 'AnonStudyID', 'StudyInstanceUID',\n",
      "        'SeriesInstanceUID', 'Manufacturer', 'NormalizedSeriesDescription', 'SeriesType'].\n",
      "    \n",
      "    overwrite: bool\n",
      "        Whether to overwrite the NIfTI file if there is already one with the same output name.\n",
      "        Defaults to False.\n",
      "    \n",
      "    cpus: int\n",
      "        Number of cpus to use for multiprocessing. Defaults to 1 (no multiprocessing).\n",
      "    \n",
      "    check_columns: bool\n",
      "        Whether to check the CSV for the required columns. Defaults to True.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    pd.DataFrame\n",
      "        A DataFrame that contains the new column: 'Nifti'. This DataFrame will be used to overwrite\n",
      "        the CSV.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from preprocessing.data import convert_batch_to_nifti\n",
    "help(convert_batch_to_nifti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5655cae9-97e4-4f60-8e65-d363f60987f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "dataset_csv = \"dicom_dataset_examples/upenn_gbm_dataset.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset_csv, dtype=str)\n",
    "\n",
    "df[\"NormalizedSeriesDescription\"] = df[\"SeriesDescription\"].apply(lambda x: \"T1Post\" if \"post\" in str(x).lower() else '')\n",
    "\n",
    "df[\"SeriesType\"] = df[\"NormalizedSeriesDescription\"].apply(lambda x: \"anat\" if x == \"T1Post\" else None)\n",
    "\n",
    "df.to_csv(dataset_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8ee11dc-52f8-42ba-bc66-48a8deacd926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to NIfTI:   0%|▎                                                                                                                                                                                                                                                                                   | 3/2270 [00:02<27:38,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/autofs/space/crater_001/datasets/public/NIH_IDC_Brain/upenn_gbm/UPENN-GBM-00263/1.3.6.1.4.1.14519.5.2.1.326397760301295542527701713877675360535/MR_1.3.6.1.4.1.14519.5.2.1.149535003298172005278901576115724126751 does not pass integrity checks and will not be converted to NIfTI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting to NIfTI: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2270/2270 [05:42<00:00,  6.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>PatientID</th>\n",
       "      <th>AccessionNumber</th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>StudyDescription</th>\n",
       "      <th>SeriesDescription</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Dicoms</th>\n",
       "      <th>AnonPatientID</th>\n",
       "      <th>AnonStudyID</th>\n",
       "      <th>NormalizedSeriesDescription</th>\n",
       "      <th>SeriesType</th>\n",
       "      <th>Nifti</th>\n",
       "      <th>Seg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.276.0.7230010.3.1.3.17436516.3156027.17205...</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.2564367332369685313507...</td>\n",
       "      <td>UPENN-GBM-00450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QIICR</td>\n",
       "      <td>20110910</td>\n",
       "      <td>BrainTumor</td>\n",
       "      <td>AIMI Brain MRI AI segmentation</td>\n",
       "      <td>SEG</td>\n",
       "      <td>/autofs/space/crater_001/datasets/public/NIH_I...</td>\n",
       "      <td>sub-01</td>\n",
       "      <td>ses-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.3205019030341469044367...</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.2564367332369685313507...</td>\n",
       "      <td>UPENN-GBM-00450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>20110910</td>\n",
       "      <td>BrainTumor</td>\n",
       "      <td>t2_Flair_axial: Processed_CaPTk</td>\n",
       "      <td>MR</td>\n",
       "      <td>/autofs/space/crater_001/datasets/public/NIH_I...</td>\n",
       "      <td>sub-01</td>\n",
       "      <td>ses-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.276.0.7230010.3.1.3.17436516.3155769.17205...</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.1266203829456751464071...</td>\n",
       "      <td>UPENN-GBM-00450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QIICR</td>\n",
       "      <td>20110910</td>\n",
       "      <td>BrainTumor</td>\n",
       "      <td>AIMI Brain MRI AI segmentation</td>\n",
       "      <td>SEG</td>\n",
       "      <td>/autofs/space/crater_001/datasets/public/NIH_I...</td>\n",
       "      <td>sub-01</td>\n",
       "      <td>ses-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.3046573623188230926346...</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.1266203829456751464071...</td>\n",
       "      <td>UPENN-GBM-00450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>20110910</td>\n",
       "      <td>BrainTumor</td>\n",
       "      <td>t1 axial_ 3D: Processed_CaPTk</td>\n",
       "      <td>MR</td>\n",
       "      <td>/autofs/space/crater_001/datasets/public/NIH_I...</td>\n",
       "      <td>sub-01</td>\n",
       "      <td>ses-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.1840500037272730575369...</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.1821188704518021360282...</td>\n",
       "      <td>UPENN-GBM-00450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>20110910</td>\n",
       "      <td>BrainTumor</td>\n",
       "      <td>ep2d_DTI_30dir</td>\n",
       "      <td>MR</td>\n",
       "      <td>/autofs/space/crater_001/datasets/public/NIH_I...</td>\n",
       "      <td>sub-01</td>\n",
       "      <td>ses-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6059</th>\n",
       "      <td>1.2.276.0.7230010.3.1.3.17436516.3889651.17204...</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.3372171645775161420612...</td>\n",
       "      <td>UPENN-GBM-00046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QIICR</td>\n",
       "      <td>20040613</td>\n",
       "      <td>BRAIN^ROUTINE</td>\n",
       "      <td>AIMI Brain MRI AI segmentation</td>\n",
       "      <td>SEG</td>\n",
       "      <td>/autofs/space/crater_001/datasets/public/NIH_I...</td>\n",
       "      <td>sub-99</td>\n",
       "      <td>ses-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6060</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.3076294954827787757748...</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.3372171645775161420612...</td>\n",
       "      <td>UPENN-GBM-00046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>20040613</td>\n",
       "      <td>BRAIN^ROUTINE</td>\n",
       "      <td>Axial T2 tse: Processed_CaPTk</td>\n",
       "      <td>MR</td>\n",
       "      <td>/autofs/space/crater_001/datasets/public/NIH_I...</td>\n",
       "      <td>sub-99</td>\n",
       "      <td>ses-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6061</th>\n",
       "      <td>1.2.276.0.7230010.3.1.3.17436516.3888998.17204...</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.1977575682986953456091...</td>\n",
       "      <td>UPENN-GBM-00046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QIICR</td>\n",
       "      <td>20040613</td>\n",
       "      <td>BRAIN^SPECTROSCOPY</td>\n",
       "      <td>AIMI Brain MRI AI segmentation</td>\n",
       "      <td>SEG</td>\n",
       "      <td>/autofs/space/crater_001/datasets/public/NIH_I...</td>\n",
       "      <td>sub-99</td>\n",
       "      <td>ses-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.1547248985746940291713...</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.1977575682986953456091...</td>\n",
       "      <td>UPENN-GBM-00046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>20040613</td>\n",
       "      <td>BRAIN^SPECTROSCOPY</td>\n",
       "      <td>t2_Flair_axial: Processed_CaPTk</td>\n",
       "      <td>MR</td>\n",
       "      <td>/autofs/space/crater_001/datasets/public/NIH_I...</td>\n",
       "      <td>sub-99</td>\n",
       "      <td>ses-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.2130654115836871849119...</td>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.1086768375063875440674...</td>\n",
       "      <td>UPENN-GBM-00046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SIEMENS</td>\n",
       "      <td>20040613</td>\n",
       "      <td>BRAIN^SPECTROSCOPY</td>\n",
       "      <td>ep2d_perf 12 CC BOLUS</td>\n",
       "      <td>MR</td>\n",
       "      <td>/autofs/space/crater_001/datasets/public/NIH_I...</td>\n",
       "      <td>sub-99</td>\n",
       "      <td>ses-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6064 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      SeriesInstanceUID  \\\n",
       "0     1.2.276.0.7230010.3.1.3.17436516.3156027.17205...   \n",
       "1     1.3.6.1.4.1.14519.5.2.1.3205019030341469044367...   \n",
       "2     1.2.276.0.7230010.3.1.3.17436516.3155769.17205...   \n",
       "3     1.3.6.1.4.1.14519.5.2.1.3046573623188230926346...   \n",
       "4     1.3.6.1.4.1.14519.5.2.1.1840500037272730575369...   \n",
       "...                                                 ...   \n",
       "6059  1.2.276.0.7230010.3.1.3.17436516.3889651.17204...   \n",
       "6060  1.3.6.1.4.1.14519.5.2.1.3076294954827787757748...   \n",
       "6061  1.2.276.0.7230010.3.1.3.17436516.3888998.17204...   \n",
       "6062  1.3.6.1.4.1.14519.5.2.1.1547248985746940291713...   \n",
       "6063  1.3.6.1.4.1.14519.5.2.1.2130654115836871849119...   \n",
       "\n",
       "                                       StudyInstanceUID        PatientID  \\\n",
       "0     1.3.6.1.4.1.14519.5.2.1.2564367332369685313507...  UPENN-GBM-00450   \n",
       "1     1.3.6.1.4.1.14519.5.2.1.2564367332369685313507...  UPENN-GBM-00450   \n",
       "2     1.3.6.1.4.1.14519.5.2.1.1266203829456751464071...  UPENN-GBM-00450   \n",
       "3     1.3.6.1.4.1.14519.5.2.1.1266203829456751464071...  UPENN-GBM-00450   \n",
       "4     1.3.6.1.4.1.14519.5.2.1.1821188704518021360282...  UPENN-GBM-00450   \n",
       "...                                                 ...              ...   \n",
       "6059  1.3.6.1.4.1.14519.5.2.1.3372171645775161420612...  UPENN-GBM-00046   \n",
       "6060  1.3.6.1.4.1.14519.5.2.1.3372171645775161420612...  UPENN-GBM-00046   \n",
       "6061  1.3.6.1.4.1.14519.5.2.1.1977575682986953456091...  UPENN-GBM-00046   \n",
       "6062  1.3.6.1.4.1.14519.5.2.1.1977575682986953456091...  UPENN-GBM-00046   \n",
       "6063  1.3.6.1.4.1.14519.5.2.1.1086768375063875440674...  UPENN-GBM-00046   \n",
       "\n",
       "     AccessionNumber Manufacturer StudyDate    StudyDescription  \\\n",
       "0                NaN        QIICR  20110910          BrainTumor   \n",
       "1                NaN      SIEMENS  20110910          BrainTumor   \n",
       "2                NaN        QIICR  20110910          BrainTumor   \n",
       "3                NaN      SIEMENS  20110910          BrainTumor   \n",
       "4                NaN      SIEMENS  20110910          BrainTumor   \n",
       "...              ...          ...       ...                 ...   \n",
       "6059             NaN        QIICR  20040613       BRAIN^ROUTINE   \n",
       "6060             NaN      SIEMENS  20040613       BRAIN^ROUTINE   \n",
       "6061             NaN        QIICR  20040613  BRAIN^SPECTROSCOPY   \n",
       "6062             NaN      SIEMENS  20040613  BRAIN^SPECTROSCOPY   \n",
       "6063             NaN      SIEMENS  20040613  BRAIN^SPECTROSCOPY   \n",
       "\n",
       "                    SeriesDescription Modality  \\\n",
       "0      AIMI Brain MRI AI segmentation      SEG   \n",
       "1     t2_Flair_axial: Processed_CaPTk       MR   \n",
       "2      AIMI Brain MRI AI segmentation      SEG   \n",
       "3       t1 axial_ 3D: Processed_CaPTk       MR   \n",
       "4                      ep2d_DTI_30dir       MR   \n",
       "...                               ...      ...   \n",
       "6059   AIMI Brain MRI AI segmentation      SEG   \n",
       "6060    Axial T2 tse: Processed_CaPTk       MR   \n",
       "6061   AIMI Brain MRI AI segmentation      SEG   \n",
       "6062  t2_Flair_axial: Processed_CaPTk       MR   \n",
       "6063            ep2d_perf 12 CC BOLUS       MR   \n",
       "\n",
       "                                                 Dicoms AnonPatientID  \\\n",
       "0     /autofs/space/crater_001/datasets/public/NIH_I...        sub-01   \n",
       "1     /autofs/space/crater_001/datasets/public/NIH_I...        sub-01   \n",
       "2     /autofs/space/crater_001/datasets/public/NIH_I...        sub-01   \n",
       "3     /autofs/space/crater_001/datasets/public/NIH_I...        sub-01   \n",
       "4     /autofs/space/crater_001/datasets/public/NIH_I...        sub-01   \n",
       "...                                                 ...           ...   \n",
       "6059  /autofs/space/crater_001/datasets/public/NIH_I...        sub-99   \n",
       "6060  /autofs/space/crater_001/datasets/public/NIH_I...        sub-99   \n",
       "6061  /autofs/space/crater_001/datasets/public/NIH_I...        sub-99   \n",
       "6062  /autofs/space/crater_001/datasets/public/NIH_I...        sub-99   \n",
       "6063  /autofs/space/crater_001/datasets/public/NIH_I...        sub-99   \n",
       "\n",
       "     AnonStudyID NormalizedSeriesDescription SeriesType Nifti  Seg  \n",
       "0         ses-01                         NaN        NaN   NaN  NaN  \n",
       "1         ses-01                         NaN        NaN   NaN  NaN  \n",
       "2         ses-02                         NaN        NaN   NaN  NaN  \n",
       "3         ses-02                         NaN        NaN   NaN  NaN  \n",
       "4         ses-03                         NaN        NaN   NaN  NaN  \n",
       "...          ...                         ...        ...   ...  ...  \n",
       "6059      ses-04                         NaN        NaN   NaN  NaN  \n",
       "6060      ses-04                         NaN        NaN   NaN  NaN  \n",
       "6061      ses-05                         NaN        NaN   NaN  NaN  \n",
       "6062      ses-05                         NaN        NaN   NaN  NaN  \n",
       "6063      ses-06                         NaN        NaN   NaN  NaN  \n",
       "\n",
       "[6064 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_batch_to_nifti(\n",
    "    nifti_dir=\"/autofs/space/crater_001/datasets/public/NIH_IDC_Brain/upenn_gbm_nifti\",\n",
    "    csv=dataset_csv,\n",
    "    seg_source=\"T1Post\",\n",
    "    overwrite_nifti=False,\n",
    "    cpus=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b884322-d978-41e7-ab85-a2fdb685cc23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (preprocessing_dev)",
   "language": "python",
   "name": "preprocessing_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
